{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# LangChain Workflow Examples\n", "This notebook demonstrates how LangChain can handle workflows."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from langchain.chains import SimpleSequentialChain, ParallelChain, LLMChain\n", "from langchain.prompts import PromptTemplate\n", "from langchain.llms import OpenAI\n", "from langchain.agents import initialize_agent, Tool\n", "from langchain.memory import ConversationBufferMemory\n", "from langchain.chains import ConversationChain\n", "\n", "# Initialize Language Model\n", "llm = OpenAI(temperature=0.9)\n", "\n", "# Example 1: Sequential Chain\n", "prompt1 = PromptTemplate(template=\"What are the key topics about {topic}?\", input_variables=[\"topic\"])\n", "prompt2 = PromptTemplate(template=\"Write a short essay about {key_topics}.\", input_variables=[\"key_topics\"])\n", "chain1 = LLMChain(llm=llm, prompt=prompt1)\n", "chain2 = LLMChain(llm=llm, prompt=prompt2)\n", "sequential_workflow = SimpleSequentialChain(chains=[chain1, chain2])\n", "output1 = sequential_workflow.run(\"climate change\")\n", "print(\"Sequential Chain Output:\", output1)\n", "\n", "# Example 2: Parallel Chain\n", "prompt3 = PromptTemplate(template=\"What are the causes of {topic}?\", input_variables=[\"topic\"])\n", "prompt4 = PromptTemplate(template=\"What are the solutions to {topic}?\", input_variables=[\"topic\"])\n", "chain3 = LLMChain(llm=llm, prompt=prompt3)\n", "chain4 = LLMChain(llm=llm, prompt=prompt4)\n", "parallel_workflow = ParallelChain(chains=[chain3, chain4], input_variables=[\"topic\"])\n", "output2 = parallel_workflow.run({\"topic\": \"climate change\"})\n", "print(\"Parallel Chain Output:\", output2)\n", "\n", "# Example 3: Agents with Tools\n", "tools = [\n", "    Tool(name=\"Search\", func=lambda query: \"searching for \" + query, description=\"Searches the web.\"),\n", "    Tool(name=\"Calculator\", func=lambda query: eval(query), description=\"Performs mathematical calculations.\"),\n", "]\n", "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\")\n", "response = agent.run(\"What is 25 multiplied by 6?\")\n", "print(\"Agent Response:\", response)\n", "\n", "# Example 4: Memory-Enabled Workflow\n", "memory = ConversationBufferMemory()\n", "conversation = ConversationChain(llm=llm, memory=memory)\n", "conversation.run(\"Tell me about quantum mechanics.\")\n", "output3 = conversation.run(\"What are some applications of it?\")\n", "print(\"Conversation Memory Output:\", output3)\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python"}}, "nbformat": 4, "nbformat_minor": 2}